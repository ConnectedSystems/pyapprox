{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add latex macros$$\\newcommand{\\V}[1]{{\\boldsymbol{#1}}}\\newcommand{mean}[1]{{\\mathbb{E}\\left[#1\\right]}}\\newcommand{var}[1]{{\\mathbb{V}\\left[#1\\right]}}\\newcommand{covar}[2]{\\mathbb{C}\\text{ov}\\left[#1,#2\\right]}\\newcommand{corr}[2]{\\mathbb{C}\\text{or}\\left[#1,#2\\right]}\\newcommand{argmin}{\\mathrm{argmin}}\\def\\rv{z}\\def\\reals{\\mathbb{R}}\\def\\pdf{\\rho}\\def\\rvdom{\\Gamma}\\def\\coloneqq{\\colon=}\\newcommand{norm}{\\lVert #1 \\rVert}\\def\\argmax{\\operatorname{argmax}}\\def\\ai{\\alpha}\\def\\bi{\\beta}\\newcommand{\\dx}[1]{\\;\\mathrm{d}#1}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nMulti-index Stochastic Collocation\n==================================\nThis tutorial describes how to implement and deploy multi-index collocation to construct a surrogate of the output of a high-fidelity model using a set of lower-fidelity models of lower accuracy and cost.\n\nDespite the improved efficiency of surrogate methods relative to MC sampling, building a surrogate can still be prohibitively expensive for high-fidelity simulation models. Fortunately, a selection of models of varying fidelity and computational cost are typically available for many applications. For example, aerospace models span fluid dynamics, structural and thermal response, control systems, etc. \n\nLeveraging an ensemble of models can facilitate significant reductions in the overall computational cost of UQ, by integrating the predictions of quantities of interest (QoI) from multiple sources.\n\n\\begin{align}\\frac{\\partial u}{\\partial t}(x,t,\\rv) + \\nabla u(x,t,\\rv)-\\nabla\\cdot\\left[k(x,\\rv) \\nabla u(x,t,\\rv)\\right] &= g(x,t) \\qquad\\qquad (x,t,\\rv)\\in D\\times [0,1]\\times\\rvdom\\\\\n   u(x,t,\\rv)&=0 \\qquad\\qquad\\qquad (x,t,\\rv)\\in \\partial D\\times[0,1]\\times\\rvdom\\end{align}\n\nwith forcing $g(x,t)=(1.5+\\cos(2\\pi t))\\cos(x_1)$, and subject to the initial condition $u(x,0,\\rv)=0$. Following [NTWSIAMNA2008]_, we model the diffusivity $k$ as a random field represented by the\nKarhunen-Loeve (like) expansion (KLE)\n\n\\begin{align}\\log(k(x,\\rv)-0.5)=1+\\rv_1\\left(\\frac{\\sqrt{\\pi L}}{2}\\right)^{1/2}+\\sum_{k=2}^d \\lambda_k\\phi(x)\\rv_k,\\end{align}\n\nwith\n\n\\begin{align}\\lambda_k=\\left(\\sqrt{\\pi L}\\right)^{1/2}\\exp\\left(-\\frac{(\\lfloor\\frac{k}{2}\\rfloor\\pi L)^2}{4}\\right) k>1,  \\qquad\\qquad  \\phi(x)=\n    \\begin{cases}\n      \\sin\\left(\\frac{(\\lfloor\\frac{k}{2}\\rfloor\\pi x_1)}{L_p}\\right) & k \\text{ even}\\,,\\\\\n      \\cos\\left(\\frac{(\\lfloor\\frac{k}{2}\\rfloor\\pi x_1)}{L_p}\\right) & k \\text{ odd}\\,.\n    \\end{cases}\\end{align}\n\nwhere $L_p=\\max(1,2L_c)$, $L=\\frac{L_c}{L_p}$ and $L_c=0.5$.\n\nWe choose a random field which is effectively one-dimensional so that the error in the finite element solution is more sensitive to refinement of the mesh in the $x_1$-direction than to refinement in the $x_2$-direction.\n\nThe advection diffusion equation \\eqref{eq:advection-diffusion} is solved using linear finite elements and implicit backward-Euler timestepping implemented using `Fenics <https://fenicsproject.org/>`_. In the following we will show how solving the PDE with varying numbers of finite elements and timesteps can reduce the cost of approximating the quantity of interest\n\n\\begin{align}f(\\rv)=\\int_D u(\\rv)\\frac{1}{2\\pi\\sigma^2}\\exp\\left(-\\frac{\\lVert x-x^\\star \\rVert_2^2}{\\sigma^2}\\right)\\,dx,\\end{align}\n\nwhere $x^\\star=(0.3,0.5)$ and $\\sigma=0.16$.\nThe advection diffusion model, defined here, can be inexpensively evaluated and therefore allows for exhaustive exploration of the behavior of our proposed multi-index collocation approach.\n\nLets first consider a simple 1D example. The following sets up the problem\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pyapprox as pya\nfrom scipy.stats import uniform\nfrom pyapprox.examples.multi_index_advection_diffusion import *\nfrom pyapprox.models.wrappers import MultiLevelWrapper\n\nnmodels  = 3\nnum_vars = 1\nmax_eval_concurrency = 1\nbase_model = setup_model(num_vars,max_eval_concurrency)\nmultilevel_model=MultiLevelWrapper(\n    base_model,base_model.base_model.num_config_vars,\n    base_model.cost_function)\nvariable = pya.IndependentMultivariateRandomVariable(\n    [uniform(-np.sqrt(3),2*np.sqrt(3))],[np.arange(num_vars)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now lets us plot each model as a function of the random variable\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lb,ub = variable.get_statistics('interval',alpha=1)[0]\nnsamples = 10\nrandom_samples = np.linspace(lb,ub,nsamples)[np.newaxis,:]\nconfig_vars = np.arange(nmodels)[np.newaxis,:]\nsamples = pya.get_all_sample_combinations(random_samples,config_vars)\nvalues = multilevel_model(samples)\nvalues = np.reshape(values,(nsamples,nmodels))\n\nimport dolfin as dl\nplt.figure(figsize=(nmodels*8,2*6))\nconfig_samples = multilevel_model.map_to_multidimensional_index(config_vars)\nfor ii in range(nmodels):\n    nx,ny,dt = base_model.base_model.get_degrees_of_freedom_and_timestep(\n        config_samples[:,ii])\n    mesh = dl.RectangleMesh(dl.Point(0, 0),dl.Point(1, 1), nx, ny)\n    plt.subplot(2,nmodels,ii+1)\n    dl.plot(mesh)\n    label=r'$f_%d$'%ii\n    if ii==0:\n        ax = plt.subplot(2,nmodels,nmodels+ii+1)\n    else:\n        plt.subplot(2,nmodels,nmodels+ii+1,sharey=ax)\n    plt.plot(random_samples[0,:],values[:,ii],label=label)\n    if ii>0:\n        label=r'$f_%d-f_%d$'%(ii,ii-1)\n        plt.plot(random_samples[0,:],values[:,ii]-values[:,ii-1],label=label)\n    plt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first row shows the spatial mesh of each model and the second row depicts the model response and the discrepancy between two consecutive models. The difference between the model output decreases as the resolution of the mesh is increased. Thus as the cost of the model increases (with increasing resolution) we need less samples to resolve \n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n^^^^^^^^^^\n.. [TJWGSIAMUQ2015] `Teckentrup, A. and Jantsch, P. and Webster, C. and Gunzburger, M. A Multilevel Stochastic Collocation Method for Partial Differential Equations with Random Input Data. SIAM/ASA Journal on Uncertainty Quantification, 3(1), 1046-1074, 2015. <https://doi.org/10.1137/140969002>`_\n\n.. [HNTTCMAME2016] `Haji-Ali, A. and Nobile, F. and Tamellini, L. and Tempone, R. Multi-Index Stochastic Collocation for random PDEs. Computer Methods in Applied Mechanics and Engineering, 306, 95-122, 2016. <https://doi.org/10.1016/j.cma.2016.03.029>`_\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}